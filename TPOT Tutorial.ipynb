{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am following [this tutorial](https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPOT is an open-source Python library for **automatizing Machine Learning.**\n",
    "\n",
    "It's way of finding the best pipeline is of genetic inspiration: \"TPOT tries a pipeline, evaluates its performance, and randomly changes parts of the pipeline in search of better performing algorithms\". In fact, some of its parameters have \"biological\" names: generations, population_size, offspring_size, etc. Let's see what these mean in the [docs](http://epistasislab.github.io/tpot/api/): \n",
    "+ generations: number of iterations to optimize the ENTIRE pipeline.\n",
    "+ population_size: number of individuals to retain in the GP population every generation.\n",
    "+ offspring_size: number of offspring to produce in each GP generation. By default it equals population_size.\n",
    "\n",
    "Take into consideration that TPOT needs to include in the pipeline: preprocessing (missing value imputation, scaling, PCA, feature selection, etc.), multiple machine learning algorithms, the hyperparameters of the algorithms and the preprocessing steps and multiple ways to join the algorithms. In fact, \"TPOT will evaluate POPULATION_SIZE + GENERATIONS x OFFSPRING_SIZE pipelines in total\". \n",
    "\n",
    "That is, TPOT evaluates POPULATION_SIZE pipelines at first. Then, it changes randomly OFFSPRING_SIZE parameters/algorithms from these pipelines. And does this GENERATIONS times.\n",
    "\n",
    "It's strengths are: \n",
    "+ **Integrated with scikit**.\n",
    "+ Evaluate **efficiently many different pipelines**. \n",
    "\n",
    "Note that **it does not replace a data scientists (at least for now)**, but helps in finding faster a good algorithm. \n",
    "\n",
    "Also, **it does not contain neural network algorithms.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Classifiers\n",
    "\n",
    "*‘sklearn.naive_bayes.BernoulliNB’: { ‘alpha’: [1e-3, 1e-2, 1e-1, 1., 10., 100.], ‘fit_prior’: [True, False] },*\n",
    "\n",
    "*‘sklearn.naive_bayes.MultinomialNB’: { ‘alpha’: [1e-3, 1e-2, 1e-1, 1., 10., 100.], ‘fit_prior’: [True, False] },* \n",
    "\n",
    "*‘sklearn.tree.DecisionTreeClassifier’: { ‘criterion’: [“gini”, “entropy”], ‘max_depth’: range(1, 11), ‘min_samples_split’: range(2, 21), ‘min_samples_leaf’: range(1, 21) },*\n",
    "\n",
    "*‘sklearn.ensemble.ExtraTreesClassifier’: { ‘n_estimators’: [100], ‘criterion’: [“gini”, “entropy”], ‘max_features’: np.arange(0.05, 1.01, 0.05), ‘min_samples_split’: range(2, 21), ‘min_samples_leaf’: range(1, 21), ‘bootstrap’: [True, False] },*\n",
    "\n",
    "*‘sklearn.ensemble.RandomForestClassifier’: { ‘n_estimators’: [100], ‘criterion’: [“gini”, “entropy”], ‘max_features’: np.arange(0.05, 1.01, 0.05), ‘min_samples_split’: range(2, 21), ‘min_samples_leaf’: range(1, 21), ‘bootstrap’: [True, False] },*\n",
    "\n",
    "*‘sklearn.ensemble.GradientBoostingClassifier’: { ‘n_estimators’: [100], ‘learning_rate’: [1e-3, 1e-2, 1e-1, 0.5, 1.], ‘max_depth’: range(1, 11), ‘min_samples_split’: range(2, 21), ‘min_samples_leaf’: range(1, 21), ‘subsample’: np.arange(0.05, 1.01, 0.05), ‘max_features’: np.arange(0.05, 1.01, 0.05) },*\n",
    "\n",
    "*‘sklearn.neighbors.KNeighborsClassifier’: { ‘n_neighbors’: range(1, 101), ‘weights’: [“uniform”, “distance”], ‘p’: [1, 2] },*\n",
    "\n",
    "*‘sklearn.svm.LinearSVC’: { ‘penalty’: [“l1”, “l2”], ‘loss’: [“hinge”, “squared_hinge”], ‘dual’: [True, False], ‘tol’: [1e-5, 1e-4, 1e-3, 1e-2, 1e-1], ‘C’: [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.] },*\n",
    "\n",
    "*‘sklearn.linear_model.LogisticRegression’: { ‘penalty’: [“l1”, “l2”], ‘C’: [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.], ‘dual’: [True, False] },*\n",
    "\n",
    "*‘xgboost.XGBClassifier’: { ‘n_estimators’: [100], ‘max_depth’: range(1, 11), ‘learning_rate’: [1e-3, 1e-2, 1e-1, 0.5, 1.], ‘subsample’: np.arange(0.05, 1.01, 0.05), ‘min_child_weight’: range(1, 21), ‘nthread’: [1] }*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition, classifiers can be stacked one on top of another, using the predictions of the first as inputs for the second.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Preprocessors\n",
    "\n",
    "*‘sklearn.preprocessing.Binarizer’: { ‘threshold’: np.arange(0.0, 1.01, 0.05) },*\n",
    "\n",
    "*‘sklearn.decomposition.FastICA’: { ‘tol’: np.arange(0.0, 1.01, 0.05) },* \n",
    "\n",
    "*‘sklearn.cluster.FeatureAgglomeration’: { ‘linkage’: [‘ward’, ‘complete’, ‘average’], ‘affinity’: [‘euclidean’, ‘l1’, ‘l2’, ‘manhattan’, ‘cosine’] },* \n",
    "\n",
    "*‘sklearn.preprocessing.MaxAbsScaler’: { },* \n",
    "\n",
    "*‘sklearn.preprocessing.MinMaxScaler’: { },* \n",
    "\n",
    "*‘sklearn.preprocessing.Normalizer’: { ‘norm’: [‘l1’, ‘l2’, ‘max’] },* \n",
    "\n",
    "*‘sklearn.kernel_approximation.Nystroem’: { ‘kernel’: [‘rbf’, ‘cosine’, ‘chi2’, ‘laplacian’, ‘polynomial’, ‘poly’, ‘linear’, ‘additive_chi2’, ‘sigmoid’], ‘gamma’: np.arange(0.0, 1.01, 0.05), ‘n_components’: range(1, 11) },* \n",
    "\n",
    "*‘sklearn.decomposition.PCA’: { ‘svd_solver’: [‘randomized’], ‘iterated_power’: range(1, 11) },*\n",
    "\n",
    "*‘sklearn.preprocessing.PolynomialFeatures’: { ‘degree’: [2], ‘include_bias’: [False], ‘interaction_only’: [False] },*\n",
    "\n",
    "*‘sklearn.kernel_approximation.RBFSampler’: { ‘gamma’: np.arange(0.0, 1.01, 0.05) }, ‘sklearn.preprocessing.RobustScaler’: { },*\n",
    "\n",
    "*‘sklearn.preprocessing.StandardScaler’: { }, ‘tpot.builtins.ZeroCount’: { }, \n",
    "‘tpot.builtins.OneHotEncoder’: { ‘minimum_fraction’: [0.05, 0.1, 0.15, 0.2, 0.25], ‘sparse’: [False] } (emphasis mine)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(verbosity=3, # see output as it is trained\n",
    "                      periodic_checkpoint_folder='folder_for_pipelines', # folder where Python code for some pipelines will be stored\n",
    "                      n_jobs=-1) # use all cores\n",
    "tpot.fit(X_train, y_train)\n",
    "tpot.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPOT does not retrieve always the same results, even if we set a seed at the beginning! That is because some algorithms have their own random_state parameters and we cannot touch them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=40, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.9754358374956306\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=7, RandomForestClassifier__n_estimators=100)\n",
      "-2\t0.9839803080877585\tKNeighborsClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.9754358374956306\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=7, RandomForestClassifier__n_estimators=100)\n",
      "-2\t0.9839803080877585\tKNeighborsClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Saving periodic pipeline from pareto front to tpot_mnst1.txt\\pipeline_gen_2_idx_0_2019.05.05_21-53-18.py\n",
      "Saving periodic pipeline from pareto front to tpot_mnst1.txt\\pipeline_gen_2_idx_1_2019.05.05_21-53-18.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.9847656104355925\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "-3\t0.9847876148637832\tKNeighborsClassifier(DecisionTreeClassifier(ZeroCount(input_matrix), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=40, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.9754358374956306\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=7, RandomForestClassifier__n_estimators=100)\n",
      "-2\t0.9839803080877585\tKNeighborsClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.9754358374956306\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=7, RandomForestClassifier__n_estimators=100)\n",
      "-2\t0.9839803080877585\tKNeighborsClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Saving periodic pipeline from pareto front to tpot_mnst1.txt\\pipeline_gen_2_idx_0_2019.05.05_21-54-02.py\n",
      "Saving periodic pipeline from pareto front to tpot_mnst1.txt\\pipeline_gen_2_idx_1_2019.05.05_21-54-02.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.9847656104355925\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "-3\t0.9847876148637832\tKNeighborsClassifier(DecisionTreeClassifier(ZeroCount(input_matrix), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=40, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.9754358374956306\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=7, RandomForestClassifier__n_estimators=100)\n",
      "-2\t0.9839803080877585\tKNeighborsClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.9754358374956306\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=7, RandomForestClassifier__n_estimators=100)\n",
      "-2\t0.9839803080877585\tKNeighborsClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Saving periodic pipeline from pareto front to tpot_mnst1.txt\\pipeline_gen_2_idx_0_2019.05.05_21-54-44.py\n",
      "Saving periodic pipeline from pareto front to tpot_mnst1.txt\\pipeline_gen_2_idx_1_2019.05.05_21-54-44.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.9847656104355925\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "-3\t0.9847876148637832\tKNeighborsClassifier(DecisionTreeClassifier(ZeroCount(input_matrix), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=15), KNeighborsClassifier__n_neighbors=13, KNeighborsClassifier__p=2, KNeighborsClassifier__weights=uniform)\n",
      "\n",
      "Times: [0.7521859725316365, 0.7261150280634562, 0.6895630955696106]\n",
      "Scores: [0.9858264878495311, 0.9858264878495311, 0.9858264878495311]\n",
      "Winning pipelines: [Pipeline(memory=None,\n",
      "     steps=[('zerocount', ZeroCount()), ('stackingestimator', StackingEstimator(estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples...i',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
      "           weights='uniform'))]), Pipeline(memory=None,\n",
      "     steps=[('zerocount', ZeroCount()), ('stackingestimator', StackingEstimator(estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples...i',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
      "           weights='uniform'))]), Pipeline(memory=None,\n",
      "     steps=[('zerocount', ZeroCount()), ('stackingestimator', StackingEstimator(estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples...i',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
      "           weights='uniform'))])]\n"
     ]
    }
   ],
   "source": [
    "# import the usual stuff\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "# import TPOT and sklearn stuff\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "# create train and test sets\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, train_size=0.75, test_size=0.25, random_state=34)\n",
    "tpot = TPOTClassifier(verbosity=3, \n",
    "                      scoring=\"balanced_accuracy\", \n",
    "                      random_state=23, \n",
    "                      periodic_checkpoint_folder=\"tpot_mnst1\", \n",
    "                      n_jobs=-1, \n",
    "                      generations=3, \n",
    "                      population_size=10)\n",
    "# run three iterations and time them\n",
    "times=[]\n",
    "winning_pipes = []\n",
    "scores = []\n",
    "\n",
    "for x in range(3):\n",
    "    start_time = time.time()\n",
    "    tpot.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start_time\n",
    "    times.append(elapsed)\n",
    "    winning_pipes.append(tpot.fitted_pipeline_)\n",
    "    scores.append(tpot.score(X_test, y_test))\n",
    "    tpot.export('tpot_mnist_pipeline.py')\n",
    "times = [time/60 for time in times]\n",
    "print('Times:', times)\n",
    "print('Scores:', scores)   \n",
    "print('Winning pipelines:', winning_pipes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
